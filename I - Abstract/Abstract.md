# Abstract

Understanding is often treated as a semantic or representational function, yet most complex systems, biological, bureaucratic, or artificial, operate without semantic comprehension in the human sense. This paper proposes a formal metric for structural comprehension, defined as the system’s capacity to integrate relational information and broadcast it coherently across its operational topology. The model introduces

C<sub>s</sub> = Φ<sub>i</sub> × R<sub>g</sub>

where Φ<sub>i</sub> represents integrated relational information (an extension of Tononi’s Φ in Integrated Information Theory), and R<sub>g</sub> denotes rhythmic reach, derived from the global broadcasting dynamics in Global Workspace Theory. Together, these parameters yield a multiplicative indicator of structural understanding, the degree to which a system both coheres internally and projects that coherence through rhythmic propagation. The paper outlines the theoretical basis of C<sub>s</sub>, and proposes operationalization methods using entropy, coherence, and broadcasting indices, and sketches potential testing scenarios in neural, organizational, and digital systems. The goal is not to claim empirical verification, but to invite interdisciplinary collaboration to evaluate C<sub>s</sub> as a predictive metric for systemic comprehension.

## Explanation

Structural comprehension is defined as the system’s capacity to integrate relational information and broadcast it coherently across its operational topology.

This phrase captures the essence of structural comprehension (C<sub>s</sub>), the core concept of the framework, by stating that understanding is not merely about accumulating information, but about the system’s ability to both integrate and distribute that information effectively.

### The three key elements:

#### 1. Integrate Relational Information (Φ<sub>i</sub>)

This element derives from Integrated Information Theory (IIT) and refers to the system’s inner unity and complexity:

Integrate – to weave separate parts into a whole.  
In a system, this means that information is not stored in isolated modules, but that each component causally influences the others.

Relational Information – information that arises from the relationships between the system’s elements, not from the elements themselves.  
For example, instead of looking at neurons individually, it concerns the patterns that emerge when they fire together.

Capacity – the ability to generate a state that cannot be explained as the sum of its parts.  
This represents the system’s internal measure of holistic awareness or inner depth.

Analogy: Mixing flour, eggs, and sugar into a cake.  
Integration is the blending process through which individual ingredients cease to exist as separate entities and become something new.

#### 2. Broadcast It Coherently (R<sub>g</sub>)

This element derives from Global Workspace Theory (GWT) and refers to the system’s ability to disseminate the integrated information:

Broadcast: to make the integrated information (the cake) available to all relevant parts of the system (to serve it to the guests).

Coherently (Synchronously): to ensure the information spreads without losing its internal structure or meaning.  
In a nervous system, this means that signals must be synchronized and reach distinct regions in the correct rhythm and sequence to generate a unified experience. This represents the system’s external measure of functional accessibility or horizontal breadth.

Analogy: Serving the cake to the guests so that they can respond to it.

Coherent broadcasting then means that every guest receives the same intact cake—not a bowl of raw ingredients.

#### 3. Across Its Operational Topology

This specifies where the integration and broadcasting must occur:

Operational Topology: the system’s actual structure or network of elements and their interconnections (whether neurons, departments in an organization, or processors in an AI).

Meaning: comprehension is a property of the functioning network as a whole.  
It does not occur in a single node, but in the geometry that defines the system’s real operating domain.

## Summary

Structural comprehension (C<sub>s</sub>) arises only when both vectors coexist simultaneously, as captured by the multiplicative formula:

C<sub>s</sub> = Φ<sub>i</sub> × R<sub>g</sub>

| Concept                    | Function                       | Scale                                 |
|----------------------------|--------------------------------|---------------------------------------|
| Integration (Φ<sub>i</sub>) | Depth of internal unity         | Vertical – how tightly connected?     |
| Broadcasting (R<sub>g</sub>) | Breadth of global dissemination | Horizontal – how far does information reach? |
| Comprehension (C<sub>s</sub>) | Predictive capacity             | Product of depth and breadth          |

If either Φ<sub>i</sub> or R<sub>g</sub> equals zero, C<sub>s</sub> collapses to zero, regardless of how high the other factor may be. This means a system may possess tremendous complexity (Φ<sub>i</sub>), but without the ability to internally broadcast it (R<sub>g</sub> = 0), it achieves no comprehension, hence the condition of “isolated intelligence” seen in current large language models and similar AI systems.

## Formalization of structural comprehension – from concept to law

Up to this point, the discussion has treated comprehension (C<sub>s</sub>) conceptually, as the emergent condition under which a system simultaneously integrates relational information and maintains rhythmic coherence across its operational topology. To move from interpretation to verification, the framework must now be expressed in formal terms.

The following proposition states, in generalizable mathematical form, the minimal conditions under which understanding can arise in any physical or informational system. It consolidates the theoretical foundation laid by Integrated Information Theory (IIT) and Global Workspace Theory (GWT) and embeds them within a unified structural equation. This marks the transition from phenomenological description to law-like formulation, where comprehension becomes a measurable and falsifiable property of structured reality.

## Proposition: a structural comprehension theorem

Statement: For any system S defined by an operational topology T consisting of interconnected elements e<sub>i</sub> with measurable relational information, the degree of structural comprehension C<sub>s</sub> is given by the product of two independent but complementary parameters:

C<sub>s</sub> = Φ<sub>i</sub> × R<sub>g</sub>

where:

Φ<sub>i</sub> denotes the integrated relational information of the system, representing internal unity and causal complexity (derived from Integrated Information Theory, IIT), and

R<sub>g</sub> denotes the rhythmic reach of the system, representing the coherence and temporal propagation of information across its topology (derived from Global Workspace Theory, GWT).

### Axioms

Integration Axiom (A₁):  
Information gains qualitative meaning only when the system’s constituent parts are causally interdependent; isolated information does not constitute comprehension.  
Φ<sub>i</sub> = 0 ⇒ C<sub>s</sub> = 0

Rhythmic Propagation Axiom (A₂):  
Integrated information must be dynamically distributed and phase-synchronized across the system to remain accessible for global function.  
R<sub>g</sub> = 0 ⇒ C<sub>s</sub> = 0

Co-Dependency Axiom (A₃):  
Integration and rhythm are orthogonal vectors of the same phenomenon: one defines depth, the other breadth. Both are necessary and neither is sufficient alone.

### Derivation

Let Φ<sub>i</sub> describe the system’s vertical coherence, the degree to which internal states constrain one another, and R<sub>g</sub> describe its horizontal coherence, the degree to which those states remain temporally synchronized and globally broadcast.

For comprehension to exist, a signal x(t) within T must satisfy both conditions:

∂x / ∂Φ<sub>i</sub> ≠ 0 and ∂x / ∂R<sub>g</sub> ≠ 0

The minimal functional form that vanishes when either parameter vanishes or grows jointly with both is the multiplicative product:

C<sub>s</sub> = f(Φ<sub>i</sub>, R<sub>g</sub>) = Φ<sub>i</sub> × R<sub>g</sub>

This yields a bilinear manifold of comprehension, where contours of equal C<sub>s</sub> represent equivalent combinations of internal unity and temporal coherence.

### Interpretation

High Φ<sub>i</sub> and high R<sub>g</sub>: maximal comprehension — adaptive, predictive, self-aware systems.  
High Φ<sub>i</sub> and low R<sub>g</sub>: encapsulated intelligence — isolated but internally complex (e.g., current LLMs).  
Low Φ<sub>i</sub> and high R<sub>g</sub>: diffuse broadcast — over-distributed systems (e.g., chaotic media networks).  
Low Φ<sub>i</sub> and low R<sub>g</sub>: fragmented systems — no coherence or understanding.

### Corollary (null collapse)

If either integration or rhythm approaches zero, comprehension collapses:

lim<sub>Φ<sub>i</sub> → 0</sub> C<sub>s</sub> = lim<sub>R<sub>g</sub> → 0</sub> C<sub>s</sub> = 0

Hence, no matter how complex or powerful a system’s internal architecture may be, without rhythmic propagation across its operational topology, understanding cannot emerge.

## Proof Sketch (Empirical Validation)

Neuroscientific evidence: high Φ (integration) and high neural synchrony co-occur during conscious states; either loss yields unconsciousness.

Artificial-system evidence: LLMs and deep networks exhibit high Φ but low R, leading to static or hallucinatory inference.

Organizational evidence: distributed decision systems with both integrative structure and rhythmic communication maintain coherence and foresight.

Therefore, across biological, artificial, and institutional domains, the empirical mapping of Φ<sub>i</sub> × R<sub>g</sub> to predictive coherence confirms the theorem’s structural validity.



---

© Tor-Ståle Hansen, https://x.com/TSHansen1971

CC BY-NC-ND 4.0  
Version: 1.0  
Initial publication: 2026-02-05  
Last modified: 2026-02-05